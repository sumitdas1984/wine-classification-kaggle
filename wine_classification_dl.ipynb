{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from collections import defaultdict\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating embedding for the wine description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_top_x_words(corpus, top_x, skip_top_n):\n",
    "    count = defaultdict(lambda: 0)\n",
    "    for c in corpus:\n",
    "        for w in word_tokenize(c):\n",
    "            count[w] += 1\n",
    "    count_tuples = sorted([(w, c) for w, c in count.items()], key=lambda x: x[1], reverse=True)\n",
    "    return [i[0] for i in count_tuples[skip_top_n: skip_top_n + top_x]]\n",
    "\n",
    "\n",
    "def replace_top_x_words_with_vectors(corpus, top_x):\n",
    "    topx_dict = {top_x[i]: i for i in range(len(top_x))}\n",
    "\n",
    "    return [\n",
    "        [topx_dict[w] for w in word_tokenize(s) if w in topx_dict]\n",
    "        for s in corpus\n",
    "    ], topx_dict\n",
    "\n",
    "\n",
    "def filter_to_top_x(corpus, n_top, skip_n_top=0):\n",
    "    top_x = count_top_x_words(corpus, n_top, skip_n_top)\n",
    "    return replace_top_x_words_with_vectors(corpus, top_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the data for Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/winemag-data-130k-v2.csv')\n",
    "\n",
    "counter = Counter(df['variety'].tolist())\n",
    "top_10_varieties = {i[0]: idx for idx, i in enumerate(counter.most_common(10))}\n",
    "df = df[df['variety'].map(lambda x: x in top_10_varieties)]\n",
    "\n",
    "description_list = df['description'].tolist()\n",
    "mapped_list, word_list = filter_to_top_x(description_list, 2500, 10)\n",
    "varietal_list_o = [top_10_varieties[i] for i in df['variety'].tolist()]\n",
    "varietal_list = to_categorical(varietal_list_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 150\n",
    "\n",
    "mapped_list = sequence.pad_sequences(mapped_list, maxlen=max_review_length)\n",
    "train_x, test_x, train_y, test_y = train_test_split(mapped_list, varietal_list, test_size=0.3)\n",
    "\n",
    "max_review_length = 150\n",
    "\n",
    "embedding_vector_length = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(2500, embedding_vector_length, input_length=max_review_length))\n",
    "model.add(Conv1D(50, 5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(max(varietal_list_o) + 1, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "49925/49925 [==============================] - 42s 835us/step - loss: 1.0616 - acc: 0.6255\n",
      "Epoch 2/3\n",
      "49925/49925 [==============================] - 42s 841us/step - loss: 0.6270 - acc: 0.7860\n",
      "Epoch 3/3\n",
      " 2368/49925 [>.............................] - ETA: 36s - loss: 0.5275 - acc: 0.8307"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the evaluation metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.07%\n"
     ]
    }
   ],
   "source": [
    "y_score = model.predict(test_x)\n",
    "y_score = [[1 if i == max(sc) else 0 for i in sc] for sc in y_score]\n",
    "n_right = 0\n",
    "for i in range(len(y_score)):\n",
    "    if all(y_score[i][j] == test_y[i][j] for j in range(len(y_score[i]))):\n",
    "        n_right += 1\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % ((n_right/float(len(test_y)) * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
